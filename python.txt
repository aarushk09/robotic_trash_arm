from tensorflow.keras.models import load_model
import cv2
import numpy as np
import ctypes
import serial
import time

np.set_printoptions(suppress=True)

# ---------- SERIAL ----------
ser = serial.Serial("COM4", 9600, timeout=1)
time.sleep(2)

# ---------- MODEL ----------
model = load_model("C:\\Users\\aarus\\Downloads\\converted_keras\\keras_model.h5", compile=False)
class_names = [l.strip() for l in open("C:\\Users\\aarus\\Downloads\\converted_keras\\labels.txt")]

# ---------- CAMERA ----------
camera = cv2.VideoCapture(0)

user32 = ctypes.windll.user32
screen_w = user32.GetSystemMetrics(0)
screen_h = user32.GetSystemMetrics(1)

window_w = int(screen_w * 0.6)
window_h = int(screen_h * 0.6)

ret, frame = camera.read()
if not ret:
    raise RuntimeError("Camera error")

cam_h, cam_w = frame.shape[:2]
scale = min(window_w / cam_w, window_h / cam_h)
display_w = int(cam_w * scale)
display_h = int(cam_h * scale)

box_size = int(display_h * 0.3)
gap = int((display_w - 3 * box_size) / 4)

middle_x = int((display_w - box_size) / 2)
y_pos = int((display_h - box_size) / 2)

boxes = [
    (middle_x - box_size - gap, y_pos),
    (middle_x, y_pos),
    (middle_x + box_size + gap, y_pos)
]

def predict_roi(frame, x, y, s):
    roi = frame[y:y+s, x:x+s]
    roi = cv2.resize(roi, (224, 224))
    roi = np.asarray(roi, dtype=np.float32).reshape(1, 224, 224, 3)
    roi = (roi / 127.5) - 1
    p = model.predict(roi, verbose=0)
    i = np.argmax(p)
    return class_names[i], float(p[0][i])

class StatusAction:
    def __init__(self):
        self.text = None
        self.color = (0, 0, 255)
        self.active = False

    def start(self, text):
        self.text = text
        self.active = True

    def draw(self, frame):
        if not self.active:
            return
        (w, _), _ = cv2.getTextSize(self.text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)
        x = (display_w - w) // 2
        y = int(display_h * 0.1)
        cv2.putText(frame, self.text, (x, y),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, self.color, 3)

status = StatusAction()
latest_results = []

def send_classification(results):
    ser.write(b"BEGIN\n")
    ser.write(b"MODE:CLASSIFICATION\n")
    for i, (label, conf) in enumerate(results, 1):
        ser.write(f"AREA {i}:{label},{conf:.2f}\n".encode())
    ser.write(b"END\n")

def send_test(angle):
    ser.write(b"BEGIN\n")
    ser.write(b"MODE:TEST\n")
    ser.write(f"ANGLE:{angle}\n".encode())
    ser.write(b"END\n")

while True:
    ret, frame = camera.read()
    if not ret:
        break

    frame = cv2.resize(frame, (display_w, display_h))
    latest_results = []

    for (x, y) in boxes:
        cv2.rectangle(frame, (x, y), (x + box_size, y + box_size), (0, 255, 0), 2)
        label, conf = predict_roi(frame, x, y, box_size)
        latest_results.append((label, conf))

        text = f"{label} {int(conf*100)}%"
        (tw, _), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
        cv2.putText(frame, (text),
                    (x + (box_size - tw) // 2, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

    status.draw(frame)
    cv2.imshow("Webcam Image", frame)

    key = cv2.waitKey(1) & 0xFF

    if key == ord('1'):
        status.start("STARTED PROCESS")
        send_classification(latest_results)

    if ord('2') <= key <= ord('8'):
        angle = (key - ord('1')) * 20
        status.start(f"TEST @ {angle}Â°")
        send_test(angle)

    if key == 27:
        break

camera.release()
ser.close()
cv2.destroyAllWindows()
